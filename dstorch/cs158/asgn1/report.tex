\documentclass[11pt]{article}

\usepackage{fullpage}

\parskip 7pt
\parindent 0pt

\title{Project 1 Report}
\author{David Storch and Matt Mahoney \\
	logins: dstorch, mjmahone}
\date{23 February 2011}

\begin{document}

\maketitle

\section{Question 1}

The dictionary of our inverted index is implemented as a hash map. The keyset is the set of all terms in the collection, and
each term hashes to the postings list. The postings lists are implemented as tree sets containing docIDs. We also keep a hash map
for each term in which the keys are docIDs and the values are lists of positions. This allows us to access positional data
when processing free text queries.

The format of the inverted index is a text file in which each line corresponds to a term in the inverted index.
The format of each line of the file is as shown below:
\begin{verbatim}
<term> : <docID> <position> <position> ... : <docID> <position> <position> ...
\end{verbatim}
The first colon-separated field contains the dictionary term, and
the remainder of the colon-separated fields contain a docID followed by a list of document positions.

\section{Question 2}

Our inverted index is well designed for frequent insertions. Since our posting lists are implemented
as tree sets, they support fast insertions. Similarly, the hash maps storing the positions support
fast insertion. The advantage of using the tree set to store the docIDs is that we can iterate over
the set in sorted order, thus allowing us to process boolean queries quickly.

\section{Question 3}

We wrote some code to create a histogram giving the distribution of posting list lengths.
The results of this analysis are given below:

\centering
\begin{tabular}{|c|c|}
\hline
\textbf{posting list length} & \textbf{frequency} \\
\hline
1 & 342,938 \\
2-10 & 208,346 \\
11-100 & 50,471 \\
101-1000 & 11,366 \\
1001-10000 & 3,022 \\
10001-100000 & 569 \\
$>$ 100000 & 11 \\
\hline
total & 616,723 \\
\hline
\end{tabular}

\flushleft
As we might have anticipated, most terms appear in the collection very infrequently (i.e., between
1 and 10 times). However, there are 580 terms that appear more than 10,000 times and 11 terms
that appear more than 100,000 times.

\section{Question 4}

A stop word list can be generated by processing the input collection without removing stop words;
then, the resulting inverted index can be searched to find the words that appear with the highest
frequency in the corpus, and these become the stop words. 

If you are using a positional index, then the collection has to be reprocessed in order to produce
an updated inverted index using the new stop words. For the phrase ``Last of the Mohicans'', our new
positional index should treat ``Last'' and ``Mohicans'' as adjacent (because ``of'' and ``the'' are stop words).

\section{Question 5}

We process boolean queries by using the native union and intersection functionality of Python sets---union for OR
and intersection for AND. Given the underlying implementation of sets as trees, the union and intersection operations
are quite enough for our needs, and we did not have to optimize using skip pointers.

We process phrase queries first by getting the set of docIDs which is the intersection of the docID sets corresponding
to each input term.

In order to determine which of these docIDs contain the query terms in the proper order, we produce updated position lists by subtracting
the index of each query term from its existing position lists. For the query, ``binary search tree'' we subtract 0 from
the position lists for ``binary'', 1 from the position lists for ``search'', and 2 from the position lists for ``tree''.
A docID which contains ``binary search tree'' should then have associated position lists which all list the same position.
Therefore, a given docID matches the query if the intersection of its updated position lists is nonempty.



\end{document}
